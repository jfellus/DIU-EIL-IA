{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modèles génératifs markoviens\n",
    "\n",
    "Dans ce TP, nous allons étudier la possibilité de générer du texte en langage naturel via une modélisation statistique.\n",
    "\n",
    "Les langages naturels (le français, l'anglais etc) sont à la fois fortement structurés et très riches :\n",
    "* On peut écrire une infinité de phrases correctes différentes\n",
    "* L'immense majorité des suites de mots ne forme pas des phrases\n",
    "\n",
    "La structuration grammaticale du langage entraîne que la distribution de fréquence marginale d'un mot est très différente de celle conditionnée par son contexte (*i.e.*, étant donnés les mots qui précèdent) : \n",
    "\n",
    "$$ P(X_i) \\neq P(X_i|X_{i-1},\\dots,X_1) $$\n",
    "\n",
    "Or on peut raisonnablement considérer qu'un page particulière d'un romab particulier, qui contient entre 250 et 280 mots, identifie de manière unique le roman en question. Cela implique que le mot qui suit immédiatement cette page est determiné de manière unique dans l'ensemble de la production litteraire de l'humanité. Il en résulte que pour une page originale grammaticalement correcte, aucune donnée statistique n'est disponible pour determiner la probabilité qu'un mot particulier ne vienne ensuite. \n",
    "\n",
    "Notre rêve de pouvoir simplement modéliser la distribution de probabilité jointe $P(X_1,\\dots,X_100000)$ de tous les livres de 100000 mots possibles et de simplement en tirer un au hasard s'évanouit définitivement...\n",
    "\n",
    "Notons également qu'une telle distribution possède $n^100000$ dimensions où $n$ est le nombre de mots valides de la langue. Notre cause est donc désespérée\n",
    "\n",
    "Nous allons donc devoir considérer un **contexte limité**. \n",
    "\n",
    "**Définition - Chaîne de Markov:** Une chaîne de Markov est une suite de variables aléatoires $(X_i)_i$ telle que \n",
    "\n",
    "$$ P(X_i+1|X_i) = P(X_i+1|X_i,\\dots,X_1) $$\n",
    "\n",
    "Autrement dit, la distribution de la prochaine variable ne dépend que de la variable actuelle. Une telle chaîne de Markov est dite \"sans mémoire\", car elle \"oublie\" le contexte antérieur.\n",
    "\n",
    "La génération d'une suite de mots par une chaîne de Markov ne necessite alors que la matrice $P:(X_{i+1},X_i)\\mapsto [0,1]$, appelée \"matrice de transition\".\n",
    "\n",
    "On peut également relacher progressivement l'hypothèse forte de Markov en observant un contexte d'horizon fini ($k$ derniers mots). Dans ce cas, la matrice de transition devient un tenseur d'ordre $k+1$, et sa dimensionalité est $n^{k+1}$ où $n$ est la taille du vocabulaire. Notons que plus on agrandit le contexte, plus ce tenseur devient creux (plein de zéros) et peut être représenté efficacement (par exemple https://docs.scipy.org/doc/scipy/reference/sparse.html)\n",
    "\n",
    "\n",
    "Dans ce TP nous allons explorer les capacités d'une IA markovienne qui :\n",
    "- rédige automatiquement des SMS d'amour\n",
    "- complète automatiquement les SMS d'amour que l'humain rédige\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Affichage joli\n",
    "def ecrit(mot):\n",
    "    global point\n",
    "    mot = mot.capitalize() if point else mot.lower()\n",
    "    if mot not in '.,?!':\n",
    "        point = mot in '.?!'\n",
    "        print(\" \", end='')\n",
    "    else:\n",
    "        point = True\n",
    "    print(mot, end='')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generation via la probabilité marginale\n",
    "import numpy as np\n",
    "\n",
    "with open(\"sms.txt\", \"r\") as f:\n",
    "    texte = f.read().split(\"\\n\")\n",
    "\n",
    "index = {}\n",
    "for w in texte:\n",
    "    index[w] = index.get(w, 0) + 1\n",
    "    \n",
    "    \n",
    "p = np.array(list(index.values()))\n",
    "p = p / sum(p)\n",
    "\n",
    "point = False\n",
    "for i in range(1000):\n",
    "    mot = np.random.choice(list(index.keys()), p=p)\n",
    "    ecrit(mot)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{k: v for k, v in sorted(index.items(), key=lambda x: x[1], reverse=True)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# C'est pas de la grande litterature...\n",
    "\n",
    "# Generation via une chaine de Markov \"stricte\"\n",
    "\n",
    "n = len(index)\n",
    "M = np.zeros((n,n))\n",
    "rev = {w:i for i,w in enumerate(index.keys())}\n",
    "\n",
    "for a,b in zip(texte,texte[1:]):\n",
    "    M[rev[a],rev[b]] += 1    \n",
    "    \n",
    "mot = '.'\n",
    "point = False\n",
    "for i in range(1000):\n",
    "    mot = np.random.choice(list(index.keys()), p=M[rev[mot]]/sum(M[rev[mot]]))\n",
    "    ecrit(mot)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On se sent déjà un peu mieux courtisé !\n",
    "\n",
    "# Generation via une chaine de Markov avec un contexte de longueur 2\n",
    "\n",
    "import re\n",
    "\n",
    "n = len(index)\n",
    "M = {}\n",
    "rev = {w:i for i,w in enumerate(index.keys())}\n",
    "\n",
    "def cle(a,b):\n",
    "    def encode(x):\n",
    "        return re.sub(r'[^\\w]', 'SP', x.lower().replace('.','POINT').replace(',',\"VIRGULE\").replace('?', 'QUEST'))\n",
    "    return (encode(a),encode(b))\n",
    "\n",
    "for a,b,c in zip(texte,texte[1:],texte[2:]):\n",
    "    if cle(a,b) not in M:\n",
    "        M[cle(a,b)] = np.zeros(n)\n",
    "    M[cle(a,b)][rev[c]] += 1    \n",
    "\n",
    "a = '.'\n",
    "b = '.'\n",
    "point = False\n",
    "for i in range(1000):\n",
    "    mot = np.random.choice(list(index.keys()), p=M[cle(a,b)]/sum(M[cle(a,b)]))\n",
    "    ecrit(mot)\n",
    "    a = b\n",
    "    b = mot\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generation via une chaine de Markov avec un contexte de longueur k donné\n",
    "\n",
    "import re\n",
    "\n",
    "K = 1\n",
    "\n",
    "n = len(index)\n",
    "M = {}\n",
    "rev = {w:i for i,w in enumerate(index.keys())}\n",
    "\n",
    "def cle(x):\n",
    "    def encode(x):\n",
    "        return x.lower().replace('.','POINT').replace(',',\"VIRGULE\").replace('?', 'QUEST')\n",
    "    return tuple([encode(x) for x in x])\n",
    "\n",
    "for i,w in enumerate(texte[:-K]):\n",
    "    contexte = [ texte[i+j] for j in range(K) ]\n",
    "    mot = texte[i+K]\n",
    "    c = cle(contexte)\n",
    "    if c not in M:\n",
    "        M[c] = np.zeros(n)\n",
    "    M[c][rev[mot]] += 1    \n",
    "\n",
    "contexte = list(M.keys())[np.random.randint(len(M.keys()))]\n",
    "point = False\n",
    "for i in range(1000):\n",
    "    c = cle(contexte)\n",
    "    mot = np.random.choice(list(index.keys()), p=M[c]/sum(M[c]))\n",
    "    _mot = mot.capitalize() if point else mot.lower()\n",
    "    if mot not in '.,?!':\n",
    "        point = mot in '.?!'\n",
    "        print(\" \", end='')\n",
    "    else:\n",
    "        point = True\n",
    "    print(_mot, end='')\n",
    "    contexte = contexte[1:] + (mot,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> A vous de jouer : testez avec un contexte de longueur $k$ arbitraire. \n",
    "\n",
    "> Que se passe-t-il lorsqu'on augment trop $k$ ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "\n",
    "S = 3\n",
    "\n",
    "t = widgets.Textarea(\n",
    "    value='',\n",
    "    placeholder=\"Tapez votre SMS d'amour assisté\",\n",
    "    description=\"Mon SMS d'amout assisté:\",\n",
    "    disabled=False\n",
    ")\n",
    "suggestions = [widgets.Button(description=\"\") for _ in range(S)]\n",
    "\n",
    "def proposer_mots(contexte, nb_suggestions):\n",
    "    c = cle(contexte)\n",
    "    mots = np.random.choice(list(index.keys()), p=M[c]/sum(M[c]), size=nb_suggestions)\n",
    "    return mots\n",
    "\n",
    "def on_change(change):\n",
    "    try:\n",
    "        mots = t.value.strip().replace(\".\", \"\").replace(\",\", \"\").lower().split(\" \")\n",
    "        contexte = mots[-K:]\n",
    "        s = proposer_mots(contexte, S)\n",
    "        for btn, sug in zip(suggestions, s):\n",
    "            btn.description = sug\n",
    "    except:\n",
    "        for btn in suggestions:\n",
    "            btn.description = \"\"\n",
    "t.observe(on_change)\n",
    "\n",
    "def accepter_suggestion(x):\n",
    "    t.value += \" \" + x.description\n",
    "\n",
    "display(t)\n",
    "for s in suggestions:\n",
    "    s.on_click(accepter_suggestion)\n",
    "    display(s)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
