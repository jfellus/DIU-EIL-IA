{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RAPPEL : Classification plus proche voisin (Nearest Neighbor)\n",
    "\n",
    "## Classification \n",
    "\n",
    "Problème d'apprentissage statistique **supervisé**\n",
    "\n",
    "Il existe une fonction inconnue $f:A\\mapsto B$ qui associe à chaque élément du domaine $A$ un élement de l'ensemble **fini** $B$. On assimile généralement $B$ à $\\{1,\\dots,|B|\\}$.  \n",
    "\n",
    "Lorsque $|B|=2$, on parle de classification binaire. \n",
    "\n",
    "BUT : Trouver une fonction $f^*:A\\mapsto B$ qui \"s'approche le plus possible\" de $f$ dans un ensemble de fonctions $F$ donné. \n",
    "\n",
    "ETANT DONNÉ :\n",
    "* un **ensemble d'apprentissage** de $n$ couples $\\{(x_i,f(x_i))\\}_i^n$ \n",
    "* un **ensemble de test** de $m$ couples $\\{(x_j,f(x_j))\\}_j^m$ \n",
    "\n",
    "* Étape 1 - Apprentissage : Pour chercher $f^*$, on ne peut utiliser que l'ensemble d'apprentissage. $f^*$ ne dépend ainsi que des $x_i$\n",
    "* Étape 2 - Evaluation : La qualité de la solution $f^*$ trouvée est ensuite mesurée sur l'ensemble de test, par exemple en comptant les \"bonnes réponses\", *i.e.*,  les $x_j$ pour lesquels $f(x_j)=f^*(x_j)$ \n",
    "\n",
    "Exemples :\n",
    "* SMS $\\mapsto \\{SPAM,OK\\}$\n",
    "* ImageDeFeuDeSignalisation $\\mapsto \\{ROUGE, ORANGE, VERT\\}$\n",
    "* PhotoDIdentité $\\mapsto$ NomDeLaPersonne\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def verite(x):\n",
    "    return math.sqrt((x[0]-0.5)**2 + (x[1]-0.5)**2) < 0.3\n",
    "\n",
    "X = np.random.rand(1000, 2)\n",
    "Y = [verite(x) for x in X]\n",
    "\n",
    "X_train = X[:500]\n",
    "Y_train = Y[:500]\n",
    "X_test = X[500:]\n",
    "Y_test = Y[500:]\n",
    "\n",
    "plt.scatter(*X_train.T,c=['g' if y else 'r' for y in Y_train]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dist(a,b):\n",
    "    return (a[0]-b[0])**2 + (a[1]-b[1])**2\n",
    "\n",
    "def classificateur(x):\n",
    "    mind = None\n",
    "    for xi,yi in zip(X_train, Y_train):\n",
    "        d = dist(x,xi)\n",
    "        if mind is None or d <= mind:\n",
    "            prediction = yi \n",
    "            mind = d\n",
    "    return prediction\n",
    "\n",
    "\n",
    "Y_pred = np.array([classificateur(x) for x in X_test])\n",
    "\n",
    "plt.scatter(*X_test.T,c=['g' if y else 'r' for y in Y_pred]);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(*X_test.T,c=['g' if y else 'r' for y in Y_test]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(*X_test.T,c=['g' if y else 'r' for y in Y_pred == Y_test]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Défauts de la classification PPV\n",
    "\n",
    "* Coût calculatoire de la décision\n",
    "* On parcourt tous les points d'entraînement à chaque décision\n",
    "* Pas vraiment de séparation entre la partie \"prise de décision\" et la partie \"apprentissage\"\n",
    "* -> peut-on alors vraiment dire que PPV est bien un \"algorithme d'apprentissage\" ?\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
